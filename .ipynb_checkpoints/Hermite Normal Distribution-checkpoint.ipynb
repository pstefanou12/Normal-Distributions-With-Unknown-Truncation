{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'delphi.train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eb339a5fd621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdelphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_truncation_normal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruncatedNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdelphi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdelphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/delphi_/delphi/distributions/unknown_truncation_normal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnknownGaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExp_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruncatedNormalDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'delphi.train'"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/Users/patroklos/Desktop/delphi_')\n",
    "\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython \n",
    "\n",
    "from delphi.distributions.unknown_truncation_normal import TruncatedNormal\n",
    "from delphi import oracle\n",
    "from delphi.utils import constants as consts\n",
    "from delphi.utils.helpers import setup_store_with_metadata\n",
    "from cox.utils import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Parameters({ \n",
    "    'samples': 10000, \n",
    "    'batch_size': 10, \n",
    "    'steps': 5000, \n",
    "    'tol': 1e-1, \n",
    "    'lr': 1e-1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Data Experiment for 1 Dimensional Censored Gaussian Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "M = MultivariateNormal(ch.zeros(1), ch.ones(1, 1))\n",
    "samples = M.sample([args.samples])\n",
    "\n",
    "plt.hist(samples.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.5004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "phi = oracle.Right(Tensor([0.0]))\n",
    "indices = phi(samples).nonzero(as_tuple=False)[:,0]\n",
    "S = samples[indices]\n",
    "alpha = S.size(0) / samples.size(0)\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "\n",
    "plt.hist(S.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run algorithm to Remove Bias from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Steps | Gradient Estimate: 0.0857977569103241\n",
      "20 Steps | Gradient Estimate: 1.2880381345748901\n",
      "30 Steps | Gradient Estimate: 1.5655070543289185\n",
      "40 Steps | Gradient Estimate: 0.4538803994655609\n",
      "50 Steps | Gradient Estimate: 0.41458675265312195\n",
      "60 Steps | Gradient Estimate: 0.38730740547180176\n",
      "70 Steps | Gradient Estimate: 2.7362911701202393\n",
      "80 Steps | Gradient Estimate: 0.16144956648349762\n",
      "90 Steps | Gradient Estimate: 0.6334964632987976\n",
      "100 Steps | Gradient Estimate: 0.8473413586616516\n",
      "110 Steps | Gradient Estimate: 2.146685838699341\n",
      "120 Steps | Gradient Estimate: 0.7482309341430664\n",
      "130 Steps | Gradient Estimate: 0.6244783997535706\n",
      "140 Steps | Gradient Estimate: 2.0761828422546387\n",
      "150 Steps | Gradient Estimate: 0.43031466007232666\n",
      "160 Steps | Gradient Estimate: 0.5423434376716614\n",
      "170 Steps | Gradient Estimate: 0.2465261071920395\n",
      "180 Steps | Gradient Estimate: 0.11733224987983704\n",
      "190 Steps | Gradient Estimate: 1.0872585773468018\n",
      "200 Steps | Gradient Estimate: 0.7252256870269775\n",
      "210 Steps | Gradient Estimate: 1.0991170406341553\n",
      "220 Steps | Gradient Estimate: 0.061813969165086746\n",
      "230 Steps | Gradient Estimate: 0.7205201387405396\n",
      "240 Steps | Gradient Estimate: 1.9866087436676025\n",
      "250 Steps | Gradient Estimate: 0.24623456597328186\n",
      "260 Steps | Gradient Estimate: 0.35999542474746704\n",
      "270 Steps | Gradient Estimate: 1.2250624895095825\n",
      "280 Steps | Gradient Estimate: 0.23598185181617737\n",
      "290 Steps | Gradient Estimate: 0.3215624690055847\n",
      "300 Steps | Gradient Estimate: 1.2081161737442017\n",
      "310 Steps | Gradient Estimate: 0.28554481267929077\n",
      "320 Steps | Gradient Estimate: 0.3273918330669403\n",
      "330 Steps | Gradient Estimate: 0.06072027608752251\n",
      "340 Steps | Gradient Estimate: 0.6255798935890198\n",
      "350 Steps | Gradient Estimate: 0.7607932686805725\n",
      "360 Steps | Gradient Estimate: 0.47020092606544495\n",
      "370 Steps | Gradient Estimate: 0.11311027407646179\n",
      "380 Steps | Gradient Estimate: 0.3149530291557312\n",
      "390 Steps | Gradient Estimate: 0.03736696392297745\n",
      "400 Steps | Gradient Estimate: 0.6084367632865906\n",
      "410 Steps | Gradient Estimate: 0.2693942189216614\n",
      "420 Steps | Gradient Estimate: 0.1343207210302353\n",
      "430 Steps | Gradient Estimate: 1.0885443687438965\n",
      "440 Steps | Gradient Estimate: 0.06678794324398041\n",
      "450 Steps | Gradient Estimate: 1.1609104871749878\n",
      "460 Steps | Gradient Estimate: 0.6792649626731873\n",
      "470 Steps | Gradient Estimate: 0.09262970834970474\n",
      "480 Steps | Gradient Estimate: 0.4121609628200531\n",
      "490 Steps | Gradient Estimate: 0.38910728693008423\n",
      "500 Steps | Gradient Estimate: 1.420962929725647\n",
      "510 Steps | Gradient Estimate: 0.6526665091514587\n",
      "520 Steps | Gradient Estimate: 0.6518988609313965\n",
      "530 Steps | Gradient Estimate: 0.46986809372901917\n",
      "540 Steps | Gradient Estimate: 0.6520435214042664\n",
      "550 Steps | Gradient Estimate: 0.2984626591205597\n",
      "560 Steps | Gradient Estimate: 0.22638235986232758\n",
      "570 Steps | Gradient Estimate: 1.3914506435394287\n",
      "580 Steps | Gradient Estimate: 0.19046930968761444\n",
      "590 Steps | Gradient Estimate: 0.692384660243988\n",
      "600 Steps | Gradient Estimate: 0.04499461501836777\n",
      "610 Steps | Gradient Estimate: 3.1260194778442383\n",
      "620 Steps | Gradient Estimate: 0.2127930372953415\n",
      "630 Steps | Gradient Estimate: 0.5200737118721008\n",
      "640 Steps | Gradient Estimate: 0.4436781108379364\n",
      "650 Steps | Gradient Estimate: 0.5850680470466614\n",
      "660 Steps | Gradient Estimate: 0.2818564176559448\n",
      "670 Steps | Gradient Estimate: 0.451111763715744\n",
      "680 Steps | Gradient Estimate: 2.1788930892944336\n",
      "690 Steps | Gradient Estimate: 0.5482397079467773\n",
      "700 Steps | Gradient Estimate: 0.7728713154792786\n",
      "710 Steps | Gradient Estimate: 0.8255189061164856\n",
      "720 Steps | Gradient Estimate: 0.4805494248867035\n",
      "730 Steps | Gradient Estimate: 0.5169157385826111\n",
      "740 Steps | Gradient Estimate: 1.434375524520874\n",
      "750 Steps | Gradient Estimate: 0.3209986090660095\n",
      "760 Steps | Gradient Estimate: 0.23477135598659515\n",
      "770 Steps | Gradient Estimate: 0.2164655178785324\n",
      "780 Steps | Gradient Estimate: 1.5714573860168457\n",
      "790 Steps | Gradient Estimate: 0.09864161163568497\n",
      "800 Steps | Gradient Estimate: 0.15203829109668732\n",
      "810 Steps | Gradient Estimate: 0.665972888469696\n",
      "820 Steps | Gradient Estimate: 1.2674659490585327\n",
      "830 Steps | Gradient Estimate: 0.26506558060646057\n",
      "840 Steps | Gradient Estimate: 0.7107936143875122\n",
      "850 Steps | Gradient Estimate: 0.6511878371238708\n",
      "860 Steps | Gradient Estimate: 0.11060069501399994\n",
      "870 Steps | Gradient Estimate: 4.0851216316223145\n",
      "880 Steps | Gradient Estimate: 1.2418036460876465\n",
      "890 Steps | Gradient Estimate: 0.5030888319015503\n",
      "900 Steps | Gradient Estimate: 0.17567268013954163\n",
      "910 Steps | Gradient Estimate: 0.34641599655151367\n",
      "920 Steps | Gradient Estimate: 0.16014160215854645\n",
      "930 Steps | Gradient Estimate: 0.09741033613681793\n",
      "940 Steps | Gradient Estimate: 0.952785313129425\n",
      "950 Steps | Gradient Estimate: 0.6141356229782104\n",
      "960 Steps | Gradient Estimate: 1.2430474758148193\n",
      "970 Steps | Gradient Estimate: 0.3967740833759308\n",
      "980 Steps | Gradient Estimate: 0.14070792496204376\n",
      "990 Steps | Gradient Estimate: 0.1675042062997818\n",
      "1000 Steps | Gradient Estimate: 0.07065771520137787\n",
      "1010 Steps | Gradient Estimate: 0.6977194547653198\n",
      "1020 Steps | Gradient Estimate: 1.0806101560592651\n",
      "1030 Steps | Gradient Estimate: 0.0845145583152771\n",
      "1040 Steps | Gradient Estimate: 1.1006550788879395\n",
      "1050 Steps | Gradient Estimate: 0.2868208885192871\n",
      "1060 Steps | Gradient Estimate: 0.4095950424671173\n",
      "1070 Steps | Gradient Estimate: 1.7321674823760986\n",
      "1080 Steps | Gradient Estimate: 0.6440844535827637\n",
      "1090 Steps | Gradient Estimate: 0.29011425375938416\n",
      "1100 Steps | Gradient Estimate: 0.8913155794143677\n",
      "1110 Steps | Gradient Estimate: 0.33508792519569397\n",
      "1120 Steps | Gradient Estimate: 0.1753571480512619\n",
      "1130 Steps | Gradient Estimate: 0.5721631050109863\n",
      "1140 Steps | Gradient Estimate: 0.6735506057739258\n",
      "1150 Steps | Gradient Estimate: 0.19847054779529572\n",
      "1160 Steps | Gradient Estimate: 1.0776516199111938\n",
      "1170 Steps | Gradient Estimate: 0.1253650039434433\n",
      "1180 Steps | Gradient Estimate: 0.15992899239063263\n",
      "1190 Steps | Gradient Estimate: 0.1723467856645584\n",
      "1200 Steps | Gradient Estimate: 0.17956861853599548\n",
      "1210 Steps | Gradient Estimate: 0.0976971909403801\n",
      "1220 Steps | Gradient Estimate: 0.2176259607076645\n",
      "1230 Steps | Gradient Estimate: 0.7300981879234314\n",
      "1240 Steps | Gradient Estimate: 0.03412383049726486\n",
      "1250 Steps | Gradient Estimate: 0.7314250469207764\n",
      "1260 Steps | Gradient Estimate: 0.6972087621688843\n",
      "1270 Steps | Gradient Estimate: 0.16047203540802002\n",
      "1280 Steps | Gradient Estimate: 1.9479635953903198\n",
      "1290 Steps | Gradient Estimate: 0.16109971702098846\n",
      "1300 Steps | Gradient Estimate: 0.19109399616718292\n",
      "1310 Steps | Gradient Estimate: 0.8538978695869446\n",
      "1320 Steps | Gradient Estimate: 0.2097381353378296\n",
      "1330 Steps | Gradient Estimate: 0.2214982658624649\n",
      "1340 Steps | Gradient Estimate: 0.1674516648054123\n",
      "1350 Steps | Gradient Estimate: 0.2880619764328003\n",
      "1360 Steps | Gradient Estimate: 0.12015616148710251\n",
      "1370 Steps | Gradient Estimate: 1.351696252822876\n",
      "1380 Steps | Gradient Estimate: 0.0327753871679306\n",
      "1390 Steps | Gradient Estimate: 0.526968240737915\n",
      "1400 Steps | Gradient Estimate: 0.6122593283653259\n",
      "1410 Steps | Gradient Estimate: 0.18394823372364044\n",
      "1420 Steps | Gradient Estimate: 0.22474251687526703\n",
      "1430 Steps | Gradient Estimate: 0.18472670018672943\n",
      "1440 Steps | Gradient Estimate: 0.403557687997818\n",
      "1450 Steps | Gradient Estimate: 0.1862790882587433\n",
      "1460 Steps | Gradient Estimate: 0.3708522915840149\n",
      "1470 Steps | Gradient Estimate: 0.213144451379776\n",
      "1480 Steps | Gradient Estimate: 0.43380051851272583\n",
      "1490 Steps | Gradient Estimate: 0.31051960587501526\n",
      "1500 Steps | Gradient Estimate: 0.34643030166625977\n",
      "1510 Steps | Gradient Estimate: 0.24364463984966278\n",
      "1520 Steps | Gradient Estimate: 0.24627666175365448\n",
      "1530 Steps | Gradient Estimate: 0.7339633107185364\n",
      "1540 Steps | Gradient Estimate: 0.122146837413311\n",
      "1550 Steps | Gradient Estimate: 0.541508674621582\n",
      "1560 Steps | Gradient Estimate: 0.4467768371105194\n",
      "1570 Steps | Gradient Estimate: 0.15085729956626892\n",
      "1580 Steps | Gradient Estimate: 0.2998197376728058\n",
      "1590 Steps | Gradient Estimate: 0.5999835729598999\n",
      "1600 Steps | Gradient Estimate: 1.9472228288650513\n",
      "1610 Steps | Gradient Estimate: 0.7513376474380493\n",
      "1620 Steps | Gradient Estimate: 0.24018988013267517\n",
      "1630 Steps | Gradient Estimate: 0.2297327220439911\n",
      "1640 Steps | Gradient Estimate: 0.735587477684021\n",
      "1650 Steps | Gradient Estimate: 1.7832881212234497\n",
      "1660 Steps | Gradient Estimate: 0.2584781050682068\n",
      "1670 Steps | Gradient Estimate: 2.298609495162964\n",
      "1680 Steps | Gradient Estimate: 0.6268662214279175\n",
      "1690 Steps | Gradient Estimate: 0.058861397206783295\n",
      "1700 Steps | Gradient Estimate: 0.10124202072620392\n",
      "1710 Steps | Gradient Estimate: 0.39980676770210266\n",
      "1720 Steps | Gradient Estimate: 0.8690546751022339\n",
      "1730 Steps | Gradient Estimate: 0.14095473289489746\n",
      "1740 Steps | Gradient Estimate: 0.5282186269760132\n",
      "1750 Steps | Gradient Estimate: 0.2235935777425766\n",
      "1760 Steps | Gradient Estimate: 2.0872488021850586\n",
      "1770 Steps | Gradient Estimate: 0.6375880241394043\n",
      "1780 Steps | Gradient Estimate: 0.8595058917999268\n",
      "1790 Steps | Gradient Estimate: 0.10086677968502045\n",
      "1800 Steps | Gradient Estimate: 0.8423247337341309\n",
      "1810 Steps | Gradient Estimate: 0.4988778233528137\n",
      "1820 Steps | Gradient Estimate: 0.0908621996641159\n",
      "1830 Steps | Gradient Estimate: 0.6025174260139465\n",
      "1840 Steps | Gradient Estimate: 0.5053681135177612\n",
      "1850 Steps | Gradient Estimate: 1.3133749961853027\n",
      "1860 Steps | Gradient Estimate: 0.11790228635072708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870 Steps | Gradient Estimate: 0.1646752655506134\n",
      "1880 Steps | Gradient Estimate: 0.14631836116313934\n",
      "1890 Steps | Gradient Estimate: 1.0618531703948975\n",
      "1900 Steps | Gradient Estimate: 0.1464982032775879\n",
      "1910 Steps | Gradient Estimate: 0.871397078037262\n",
      "1920 Steps | Gradient Estimate: 0.19598104059696198\n",
      "1930 Steps | Gradient Estimate: 0.18815161287784576\n",
      "1940 Steps | Gradient Estimate: 0.24668443202972412\n",
      "1950 Steps | Gradient Estimate: 0.1453070193529129\n",
      "1960 Steps | Gradient Estimate: 0.13107506930828094\n",
      "1970 Steps | Gradient Estimate: 1.3576054573059082\n",
      "1980 Steps | Gradient Estimate: 0.8086279630661011\n",
      "1990 Steps | Gradient Estimate: 0.3158952295780182\n",
      "2000 Steps | Gradient Estimate: 0.5804123282432556\n",
      "2010 Steps | Gradient Estimate: 0.23661601543426514\n",
      "2020 Steps | Gradient Estimate: 0.04661982133984566\n",
      "2030 Steps | Gradient Estimate: 0.07081103324890137\n",
      "2040 Steps | Gradient Estimate: 0.08322139829397202\n",
      "2050 Steps | Gradient Estimate: 0.29770427942276\n",
      "2060 Steps | Gradient Estimate: 0.35917532444000244\n",
      "2070 Steps | Gradient Estimate: 0.06560628861188889\n",
      "2080 Steps | Gradient Estimate: 1.5051734447479248\n",
      "2090 Steps | Gradient Estimate: 1.137702226638794\n",
      "2100 Steps | Gradient Estimate: 0.3507160246372223\n",
      "2110 Steps | Gradient Estimate: 0.1185363233089447\n",
      "2120 Steps | Gradient Estimate: 0.5284735560417175\n",
      "2130 Steps | Gradient Estimate: 3.393213987350464\n",
      "2140 Steps | Gradient Estimate: 0.19831809401512146\n",
      "2150 Steps | Gradient Estimate: 0.4612395167350769\n",
      "2160 Steps | Gradient Estimate: 0.2341853678226471\n",
      "2170 Steps | Gradient Estimate: 1.0507622957229614\n",
      "2180 Steps | Gradient Estimate: 1.4158167839050293\n",
      "2190 Steps | Gradient Estimate: 0.19768263399600983\n",
      "2200 Steps | Gradient Estimate: 2.88287615776062\n",
      "2210 Steps | Gradient Estimate: 2.0820629596710205\n",
      "2220 Steps | Gradient Estimate: 0.8991040587425232\n",
      "2230 Steps | Gradient Estimate: 0.5382354855537415\n",
      "2240 Steps | Gradient Estimate: 0.7408127188682556\n",
      "2250 Steps | Gradient Estimate: 0.6257796883583069\n",
      "2260 Steps | Gradient Estimate: 0.8455216884613037\n",
      "2270 Steps | Gradient Estimate: 0.18182387948036194\n",
      "2280 Steps | Gradient Estimate: 1.2751997709274292\n",
      "2290 Steps | Gradient Estimate: 0.14767774939537048\n",
      "2300 Steps | Gradient Estimate: 0.10455943644046783\n",
      "2310 Steps | Gradient Estimate: 0.019308222457766533\n",
      "2320 Steps | Gradient Estimate: 0.10458873212337494\n",
      "2330 Steps | Gradient Estimate: 0.17277246713638306\n",
      "2340 Steps | Gradient Estimate: 1.256136178970337\n",
      "2350 Steps | Gradient Estimate: 0.26977071166038513\n",
      "2360 Steps | Gradient Estimate: 0.8521944284439087\n",
      "2370 Steps | Gradient Estimate: 0.18262962996959686\n",
      "2380 Steps | Gradient Estimate: 0.5598257780075073\n",
      "2390 Steps | Gradient Estimate: 0.07166828960180283\n",
      "2400 Steps | Gradient Estimate: 1.3497611284255981\n",
      "2410 Steps | Gradient Estimate: 1.3989908695220947\n",
      "2420 Steps | Gradient Estimate: 1.1795268058776855\n",
      "2430 Steps | Gradient Estimate: 0.8424245715141296\n",
      "2440 Steps | Gradient Estimate: 0.6680138111114502\n",
      "2450 Steps | Gradient Estimate: 0.18793046474456787\n",
      "2460 Steps | Gradient Estimate: 0.5493876934051514\n",
      "2470 Steps | Gradient Estimate: 2.9123666286468506\n",
      "2480 Steps | Gradient Estimate: 0.9272242784500122\n",
      "2490 Steps | Gradient Estimate: 0.14326448738574982\n",
      "2500 Steps | Gradient Estimate: 1.920047402381897\n",
      "2510 Steps | Gradient Estimate: 0.06508775800466537\n",
      "2520 Steps | Gradient Estimate: 3.77121901512146\n",
      "2530 Steps | Gradient Estimate: 0.0688575878739357\n",
      "2540 Steps | Gradient Estimate: 0.5855689644813538\n",
      "2550 Steps | Gradient Estimate: 0.3525450825691223\n",
      "2560 Steps | Gradient Estimate: 0.06455444544553757\n",
      "2570 Steps | Gradient Estimate: 0.7385993599891663\n",
      "2580 Steps | Gradient Estimate: 1.3748657703399658\n",
      "2590 Steps | Gradient Estimate: 0.4092058539390564\n",
      "2600 Steps | Gradient Estimate: 0.35587218403816223\n",
      "2610 Steps | Gradient Estimate: 0.5636280179023743\n",
      "2620 Steps | Gradient Estimate: 0.4747779369354248\n",
      "2630 Steps | Gradient Estimate: 0.334110289812088\n",
      "2640 Steps | Gradient Estimate: 0.39177998900413513\n",
      "2650 Steps | Gradient Estimate: 1.0124603509902954\n",
      "2660 Steps | Gradient Estimate: 0.1674443930387497\n",
      "2670 Steps | Gradient Estimate: 0.6157306432723999\n",
      "2680 Steps | Gradient Estimate: 0.6047196388244629\n",
      "2690 Steps | Gradient Estimate: 0.33276110887527466\n",
      "2700 Steps | Gradient Estimate: 0.07331310212612152\n",
      "2710 Steps | Gradient Estimate: 0.022223256528377533\n",
      "2720 Steps | Gradient Estimate: 0.1859847605228424\n",
      "2730 Steps | Gradient Estimate: 0.08526897430419922\n",
      "2740 Steps | Gradient Estimate: 0.6643525958061218\n",
      "2750 Steps | Gradient Estimate: 0.4413299858570099\n",
      "2760 Steps | Gradient Estimate: 0.2636074721813202\n",
      "2770 Steps | Gradient Estimate: 0.4853340685367584\n",
      "2780 Steps | Gradient Estimate: 0.3547666370868683\n",
      "2790 Steps | Gradient Estimate: 0.9298620820045471\n",
      "2800 Steps | Gradient Estimate: 0.9404101371765137\n",
      "2810 Steps | Gradient Estimate: 0.26323202252388\n",
      "2820 Steps | Gradient Estimate: 1.0727986097335815\n",
      "2830 Steps | Gradient Estimate: 0.03314671665430069\n",
      "2840 Steps | Gradient Estimate: 5.0645647048950195\n",
      "2850 Steps | Gradient Estimate: 0.40754881501197815\n",
      "2860 Steps | Gradient Estimate: 0.4392099678516388\n",
      "2870 Steps | Gradient Estimate: 0.8650298714637756\n",
      "2880 Steps | Gradient Estimate: 0.2717430293560028\n",
      "2890 Steps | Gradient Estimate: 0.3295673727989197\n",
      "2900 Steps | Gradient Estimate: 1.1813713312149048\n",
      "2910 Steps | Gradient Estimate: 0.6955448389053345\n",
      "2920 Steps | Gradient Estimate: 0.5230088829994202\n",
      "2930 Steps | Gradient Estimate: 0.14875377714633942\n",
      "2940 Steps | Gradient Estimate: 0.2802751660346985\n",
      "2950 Steps | Gradient Estimate: 0.09944973886013031\n",
      "2960 Steps | Gradient Estimate: 0.40494269132614136\n",
      "2970 Steps | Gradient Estimate: 0.20347243547439575\n",
      "2980 Steps | Gradient Estimate: 0.2893632650375366\n",
      "2990 Steps | Gradient Estimate: 0.7036407589912415\n",
      "3000 Steps | Gradient Estimate: 0.31492769718170166\n",
      "3010 Steps | Gradient Estimate: 0.2543046176433563\n",
      "3020 Steps | Gradient Estimate: 1.1793546676635742\n",
      "3030 Steps | Gradient Estimate: 0.2907828986644745\n",
      "3040 Steps | Gradient Estimate: 0.5757487416267395\n",
      "3050 Steps | Gradient Estimate: 0.0832441970705986\n",
      "3060 Steps | Gradient Estimate: 1.2782394886016846\n",
      "3070 Steps | Gradient Estimate: 2.423182487487793\n",
      "3080 Steps | Gradient Estimate: 0.3530399203300476\n",
      "3090 Steps | Gradient Estimate: 0.5674911737442017\n",
      "3100 Steps | Gradient Estimate: 0.48782238364219666\n",
      "3110 Steps | Gradient Estimate: 0.8267460465431213\n",
      "3120 Steps | Gradient Estimate: 1.321205735206604\n",
      "3130 Steps | Gradient Estimate: 0.1974869668483734\n",
      "3140 Steps | Gradient Estimate: 3.0937018394470215\n",
      "3150 Steps | Gradient Estimate: 0.3443796634674072\n",
      "3160 Steps | Gradient Estimate: 0.2803104519844055\n",
      "3170 Steps | Gradient Estimate: 0.5950773358345032\n",
      "3180 Steps | Gradient Estimate: 0.5778520703315735\n",
      "3190 Steps | Gradient Estimate: 0.3582286536693573\n",
      "3200 Steps | Gradient Estimate: 0.32991713285446167\n",
      "3210 Steps | Gradient Estimate: 0.10343614965677261\n",
      "3220 Steps | Gradient Estimate: 1.7913894653320312\n",
      "3230 Steps | Gradient Estimate: 0.214190274477005\n",
      "3240 Steps | Gradient Estimate: 0.39923858642578125\n",
      "3250 Steps | Gradient Estimate: 0.1027899906039238\n",
      "3260 Steps | Gradient Estimate: 1.092475175857544\n",
      "3270 Steps | Gradient Estimate: 1.8156611919403076\n",
      "3280 Steps | Gradient Estimate: 1.5307602882385254\n",
      "3290 Steps | Gradient Estimate: 0.40872785449028015\n",
      "3300 Steps | Gradient Estimate: 2.8544516563415527\n",
      "3310 Steps | Gradient Estimate: 0.5720296502113342\n",
      "3320 Steps | Gradient Estimate: 0.29991546273231506\n",
      "3330 Steps | Gradient Estimate: 0.9119188189506531\n",
      "3340 Steps | Gradient Estimate: 2.7912726402282715\n",
      "3350 Steps | Gradient Estimate: 0.25841477513313293\n",
      "3360 Steps | Gradient Estimate: 0.502256453037262\n",
      "3370 Steps | Gradient Estimate: 1.080094575881958\n",
      "3380 Steps | Gradient Estimate: 0.4765530824661255\n",
      "3390 Steps | Gradient Estimate: 0.9538466334342957\n",
      "3400 Steps | Gradient Estimate: 1.265753984451294\n",
      "3410 Steps | Gradient Estimate: 2.1559276580810547\n",
      "3420 Steps | Gradient Estimate: 0.602653443813324\n",
      "3430 Steps | Gradient Estimate: 0.6991573572158813\n",
      "3440 Steps | Gradient Estimate: 0.41547349095344543\n",
      "3450 Steps | Gradient Estimate: 0.30700433254241943\n",
      "3460 Steps | Gradient Estimate: 0.745084285736084\n",
      "3470 Steps | Gradient Estimate: 1.1868864297866821\n",
      "3480 Steps | Gradient Estimate: 1.333178162574768\n",
      "3490 Steps | Gradient Estimate: 0.1704479455947876\n",
      "3500 Steps | Gradient Estimate: 0.21798673272132874\n",
      "3510 Steps | Gradient Estimate: 1.0824170112609863\n",
      "3520 Steps | Gradient Estimate: 0.40308183431625366\n",
      "3530 Steps | Gradient Estimate: 1.445926547050476\n",
      "3540 Steps | Gradient Estimate: 0.8530004620552063\n",
      "3550 Steps | Gradient Estimate: 1.124798059463501\n",
      "3560 Steps | Gradient Estimate: 0.46272701025009155\n",
      "3570 Steps | Gradient Estimate: 0.36283567547798157\n",
      "3580 Steps | Gradient Estimate: 0.1260017305612564\n",
      "3590 Steps | Gradient Estimate: 0.6262291073799133\n",
      "3600 Steps | Gradient Estimate: 1.3338855504989624\n",
      "3610 Steps | Gradient Estimate: 0.5255874395370483\n",
      "3620 Steps | Gradient Estimate: 0.30256518721580505\n",
      "3630 Steps | Gradient Estimate: 0.13744255900382996\n",
      "3640 Steps | Gradient Estimate: 0.10201174765825272\n",
      "3650 Steps | Gradient Estimate: 0.47769665718078613\n",
      "3660 Steps | Gradient Estimate: 0.8162572979927063\n",
      "3670 Steps | Gradient Estimate: 0.40149521827697754\n",
      "3680 Steps | Gradient Estimate: 1.1397976875305176\n",
      "3690 Steps | Gradient Estimate: 1.970733880996704\n",
      "3700 Steps | Gradient Estimate: 0.7826194763183594\n",
      "3710 Steps | Gradient Estimate: 0.5230762958526611\n",
      "3720 Steps | Gradient Estimate: 0.19873353838920593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730 Steps | Gradient Estimate: 0.24035349488258362\n",
      "3740 Steps | Gradient Estimate: 1.8624132871627808\n",
      "3750 Steps | Gradient Estimate: 0.6003389954566956\n",
      "3760 Steps | Gradient Estimate: 0.6271575093269348\n",
      "3770 Steps | Gradient Estimate: 0.827629029750824\n",
      "3780 Steps | Gradient Estimate: 0.4880760908126831\n",
      "3790 Steps | Gradient Estimate: 0.14696040749549866\n",
      "3800 Steps | Gradient Estimate: 0.2644217312335968\n",
      "3810 Steps | Gradient Estimate: 0.11487258225679398\n",
      "3820 Steps | Gradient Estimate: 0.6538028717041016\n",
      "3830 Steps | Gradient Estimate: 1.0057851076126099\n",
      "3840 Steps | Gradient Estimate: 0.42769694328308105\n",
      "3850 Steps | Gradient Estimate: 0.4727014899253845\n",
      "3860 Steps | Gradient Estimate: 0.3875783681869507\n",
      "3870 Steps | Gradient Estimate: 0.22461234033107758\n",
      "3880 Steps | Gradient Estimate: 0.27679145336151123\n",
      "3890 Steps | Gradient Estimate: 0.4995967149734497\n",
      "3900 Steps | Gradient Estimate: 0.25638797879219055\n",
      "3910 Steps | Gradient Estimate: 0.6914442777633667\n",
      "3920 Steps | Gradient Estimate: 0.27253544330596924\n",
      "3930 Steps | Gradient Estimate: 0.21477031707763672\n",
      "3940 Steps | Gradient Estimate: 1.8380740880966187\n",
      "3950 Steps | Gradient Estimate: 2.060375928878784\n",
      "3960 Steps | Gradient Estimate: 0.3354083001613617\n",
      "3970 Steps | Gradient Estimate: 0.22268851101398468\n",
      "3980 Steps | Gradient Estimate: 0.5442106127738953\n",
      "3990 Steps | Gradient Estimate: 0.3548405170440674\n",
      "4000 Steps | Gradient Estimate: 0.7556622624397278\n",
      "4010 Steps | Gradient Estimate: 0.3987691402435303\n",
      "4020 Steps | Gradient Estimate: 0.2867053747177124\n",
      "4030 Steps | Gradient Estimate: 0.14988963305950165\n",
      "4040 Steps | Gradient Estimate: 1.0855913162231445\n",
      "4050 Steps | Gradient Estimate: 0.38497018814086914\n",
      "4060 Steps | Gradient Estimate: 0.24121969938278198\n",
      "4070 Steps | Gradient Estimate: 0.20016683638095856\n",
      "4080 Steps | Gradient Estimate: 0.4711463451385498\n",
      "4090 Steps | Gradient Estimate: 0.5538994669914246\n",
      "4100 Steps | Gradient Estimate: 1.154972791671753\n",
      "4110 Steps | Gradient Estimate: 0.4514369070529938\n",
      "4120 Steps | Gradient Estimate: 0.37738728523254395\n",
      "4130 Steps | Gradient Estimate: 0.4899693727493286\n",
      "4140 Steps | Gradient Estimate: 0.10794927924871445\n",
      "4150 Steps | Gradient Estimate: 0.6145810484886169\n",
      "4160 Steps | Gradient Estimate: 0.669628381729126\n",
      "4170 Steps | Gradient Estimate: 0.4218958914279938\n",
      "4180 Steps | Gradient Estimate: 1.5499653816223145\n",
      "4190 Steps | Gradient Estimate: 0.8400661945343018\n",
      "4200 Steps | Gradient Estimate: 0.9876279830932617\n",
      "4210 Steps | Gradient Estimate: 0.5269816517829895\n",
      "4220 Steps | Gradient Estimate: 2.3066484928131104\n",
      "4230 Steps | Gradient Estimate: 0.16816145181655884\n",
      "4240 Steps | Gradient Estimate: 0.28964340686798096\n",
      "4250 Steps | Gradient Estimate: 0.6517632603645325\n",
      "4260 Steps | Gradient Estimate: 0.5574437975883484\n",
      "4270 Steps | Gradient Estimate: 1.182208776473999\n",
      "4280 Steps | Gradient Estimate: 1.098046064376831\n",
      "4290 Steps | Gradient Estimate: 1.9411917924880981\n",
      "4300 Steps | Gradient Estimate: 0.09950994700193405\n",
      "4310 Steps | Gradient Estimate: 0.05300825089216232\n",
      "4320 Steps | Gradient Estimate: 2.0498011112213135\n",
      "4330 Steps | Gradient Estimate: 0.6231728792190552\n",
      "4340 Steps | Gradient Estimate: 0.7584841251373291\n",
      "4350 Steps | Gradient Estimate: 2.00819730758667\n",
      "4360 Steps | Gradient Estimate: 0.1518520712852478\n",
      "4370 Steps | Gradient Estimate: 0.20917558670043945\n",
      "4380 Steps | Gradient Estimate: 0.5370621681213379\n",
      "4390 Steps | Gradient Estimate: 0.47261756658554077\n",
      "4400 Steps | Gradient Estimate: 0.7771784067153931\n",
      "4410 Steps | Gradient Estimate: 0.2646592855453491\n",
      "4420 Steps | Gradient Estimate: 0.08829130232334137\n",
      "4430 Steps | Gradient Estimate: 0.23487073183059692\n",
      "4440 Steps | Gradient Estimate: 4.245086193084717\n",
      "4450 Steps | Gradient Estimate: 0.9988225698471069\n",
      "4460 Steps | Gradient Estimate: 1.329285740852356\n",
      "4470 Steps | Gradient Estimate: 0.5215339064598083\n",
      "4480 Steps | Gradient Estimate: 0.4855683743953705\n",
      "4490 Steps | Gradient Estimate: 0.8947386741638184\n",
      "4500 Steps | Gradient Estimate: 0.7061036229133606\n",
      "4510 Steps | Gradient Estimate: 0.20399680733680725\n",
      "4520 Steps | Gradient Estimate: 0.274027943611145\n",
      "4530 Steps | Gradient Estimate: 0.16032284498214722\n",
      "4540 Steps | Gradient Estimate: 0.9597562551498413\n",
      "4550 Steps | Gradient Estimate: 0.7274042367935181\n",
      "4560 Steps | Gradient Estimate: 0.8459330201148987\n",
      "4570 Steps | Gradient Estimate: 0.45393404364585876\n",
      "4580 Steps | Gradient Estimate: 0.3772842586040497\n",
      "4590 Steps | Gradient Estimate: 0.2670608162879944\n",
      "4600 Steps | Gradient Estimate: 0.22471274435520172\n",
      "4610 Steps | Gradient Estimate: 0.02163119427859783\n",
      "4620 Steps | Gradient Estimate: 0.5767629146575928\n",
      "4630 Steps | Gradient Estimate: 0.43396419286727905\n",
      "4640 Steps | Gradient Estimate: 0.10561719536781311\n",
      "4650 Steps | Gradient Estimate: 0.21043427288532257\n",
      "4660 Steps | Gradient Estimate: 0.8887020349502563\n",
      "4670 Steps | Gradient Estimate: 0.23996561765670776\n",
      "4680 Steps | Gradient Estimate: 0.295034259557724\n",
      "4690 Steps | Gradient Estimate: 0.2850034236907959\n",
      "4700 Steps | Gradient Estimate: 0.18876834213733673\n",
      "4710 Steps | Gradient Estimate: 0.3443930447101593\n",
      "4720 Steps | Gradient Estimate: 0.38521960377693176\n",
      "4730 Steps | Gradient Estimate: 0.2821522057056427\n",
      "4740 Steps | Gradient Estimate: 1.1866050958633423\n",
      "4750 Steps | Gradient Estimate: 1.555768609046936\n",
      "4760 Steps | Gradient Estimate: 0.08093664050102234\n",
      "4770 Steps | Gradient Estimate: 1.3891005516052246\n",
      "4780 Steps | Gradient Estimate: 0.5579138398170471\n",
      "4790 Steps | Gradient Estimate: 0.1380791813135147\n",
      "4800 Steps | Gradient Estimate: 0.17588110268115997\n",
      "4810 Steps | Gradient Estimate: 0.1760268658399582\n",
      "4820 Steps | Gradient Estimate: 0.6943501830101013\n",
      "4830 Steps | Gradient Estimate: 0.6765038371086121\n",
      "4840 Steps | Gradient Estimate: 2.328606605529785\n",
      "4850 Steps | Gradient Estimate: 2.5591886043548584\n",
      "4860 Steps | Gradient Estimate: 0.5436121821403503\n",
      "4870 Steps | Gradient Estimate: 0.33039575815200806\n",
      "4880 Steps | Gradient Estimate: 0.5302631258964539\n",
      "4890 Steps | Gradient Estimate: 0.08166222274303436\n",
      "4900 Steps | Gradient Estimate: 0.41297462582588196\n",
      "4910 Steps | Gradient Estimate: 0.43834733963012695\n",
      "4920 Steps | Gradient Estimate: 0.33345505595207214\n",
      "4930 Steps | Gradient Estimate: 0.16000814735889435\n",
      "4940 Steps | Gradient Estimate: 0.627713143825531\n"
     ]
    }
   ],
   "source": [
    "censored = CensoredNormal(phi=phi, alpha=alpha, steps=args.steps)\n",
    "censored.fit(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
